1
00:00:00,120 --> 00:00:01,220
If you run the learning algorithm

2
00:00:01,710 --> 00:00:02,640
and it doesn't do as well

3
00:00:02,840 --> 00:00:04,520
as you are hoping, almost all

4
00:00:04,740 --> 00:00:05,670
the time it will be because

5
00:00:06,100 --> 00:00:07,650
you have either a high bias

6
00:00:08,010 --> 00:00:09,530
problem or a high variance problem.

7
00:00:09,860 --> 00:00:10,940
In other words they're either an

8
00:00:11,130 --> 00:00:13,140
underfitting problem or an overfitting problem.

9
00:00:14,260 --> 00:00:15,090
And in this case it's very

10
00:00:15,350 --> 00:00:16,580
important to figure out

11
00:00:16,790 --> 00:00:17,970
which of these two problems is

12
00:00:18,280 --> 00:00:19,500
bias or variance or a bit of both that you

13
00:00:20,210 --> 00:00:20,430
actually have.

14
00:00:21,050 --> 00:00:21,980
Because knowing which of these

15
00:00:22,440 --> 00:00:23,890
two things is happening would give

16
00:00:24,060 --> 00:00:25,940
a very strong indicator for whether

17
00:00:26,180 --> 00:00:27,490
the useful and promising ways

18
00:00:27,770 --> 00:00:29,030
to try to improve your algorithm.

19
00:00:30,230 --> 00:00:31,270
In this video, I would like

20
00:00:31,380 --> 00:00:33,030
to delve more deeply into

21
00:00:33,220 --> 00:00:34,850
this bias and various issue and

22
00:00:35,180 --> 00:00:36,530
understand them better as well

23
00:00:36,790 --> 00:00:38,470
as figure out how to look

24
00:00:38,610 --> 00:00:42,910
at and evaluate knows whether or not we might have a bias problem or a variance problem.

25
00:00:43,030 --> 00:00:45,750
Since this would be critical to

26
00:00:45,900 --> 00:00:48,180
figuring out how to improve the performance of learning algorithm that you implement.

27
00:00:48,640 --> 00:00:52,270
So you've already

28
00:00:52,680 --> 00:00:53,690
seen this figure a few times,

29
00:00:54,190 --> 00:00:55,230
where if you fit two simple

30
00:00:55,710 --> 00:00:57,900
hypothesis, like a straight line that that underfits the data.

31
00:00:59,660 --> 00:01:00,720
If you fit a two complex

32
00:01:01,250 --> 00:01:02,870
hypothesis, then that might

33
00:01:03,400 --> 00:01:05,050
fit the training set perfectly but

34
00:01:05,270 --> 00:01:06,810
overfit the data and this

35
00:01:06,930 --> 00:01:09,000
may be hypothesis of some

36
00:01:09,340 --> 00:01:11,000
intermediate level of complexity,

37
00:01:11,810 --> 00:01:13,120
of some, maybe degree two

38
00:01:13,390 --> 00:01:15,770
polynomials are not too low and not too high degree.

39
00:01:16,560 --> 00:01:17,340
That's just right.

40
00:01:17,560 --> 00:01:18,480
And gives you the best

41
00:01:19,100 --> 00:01:20,740
generalization error out of these options.

42
00:01:21,770 --> 00:01:22,960
Now that we're armed with the

43
00:01:23,030 --> 00:01:25,130
notion of training and validation

44
00:01:26,100 --> 00:01:27,550
in test sets, we can understand

45
00:01:28,290 --> 00:01:30,530
the concepts of bias and variance a little bit better.

46
00:01:31,310 --> 00:01:33,140
Concretely, let our

47
00:01:33,370 --> 00:01:34,920
training error and cross

48
00:01:35,050 --> 00:01:36,620
validation error be defined as

49
00:01:36,850 --> 00:01:38,440
in the previous videos, just say,

50
00:01:38,680 --> 00:01:40,110
the squared error, the average

51
00:01:40,450 --> 00:01:41,420
squared error as measured

52
00:01:41,830 --> 00:01:42,810
on the 20 sets or as

53
00:01:42,930 --> 00:01:44,710
measured on the cross validation set.

54
00:01:46,560 --> 00:01:47,690
Now let's plot the following figure.

55
00:01:48,470 --> 00:01:49,930
On the horizontal axis I am

56
00:01:50,010 --> 00:01:52,000
going to plot the degree of polynomial,

57
00:01:52,400 --> 00:01:53,380
so as I go the right

58
00:01:54,810 --> 00:01:57,050
I'm going to be fitting higher and higher order polynomials.

59
00:01:58,000 --> 00:02:02,687
So will the left of this figure, where maybe D equals one, we're

60
00:02:02,687 --> 00:02:07,500
going to be fitting very simple figures.Whereas way here on the right of the

61
00:02:07,500 --> 00:02:12,187
horizontal axis, have much larger values of D. So a much higher degree of

62
00:02:12,187 --> 00:02:17,487
polynomial. And so here that's going to correspond to fitting. Much more complex

63
00:02:17,487 --> 00:02:22,836
functions to your training set. Let's look at the training error and the cross

64
00:02:22,836 --> 00:02:27,342
validation error and plot them on this figure. Let's start with the training

65
00:02:27,342 --> 00:02:32,086
error. As we increase the degree of the polynomial, we're going to be able to fit

66
00:02:32,086 --> 00:02:36,533
our training set better and better. And so, if D=1 then it's a relatively high

67
00:02:36,533 --> 00:02:41,157
training error. If we have a very high degree polynomial our training error is

68
00:02:41,157 --> 00:02:45,960
going to be really low maybe even zero because we'll fit the training set really well.

69
00:02:45,960 --> 00:02:50,644
And so as we increase the degree of polynomial, we find typically that the

70
00:02:50,644 --> 00:02:55,776
training error decreases. So, I'm going to write J. Subscript three of data there.

71
00:02:55,776 --> 00:03:01,565
Because our training error tends to decrease with the degree of polynomial

72
00:03:01,565 --> 00:03:07,652
that we fit to the data. Next let's look at the cross validation error. Or for that

73
00:03:07,652 --> 00:03:13,812
matter, if we look at the test set error we'll get a pretty similar result as if we

74
00:03:13,812 --> 00:03:19,292
were to plot the cross validation error. So, we know that if D=1. We're fitting a

75
00:03:19,292 --> 00:03:23,758
very simple function. And so we may be under fitting the training set. And so

76
00:03:23,758 --> 00:03:28,343
we're going to have a very high cross validation error. If we fit, you know, an

77
00:03:28,343 --> 00:03:33,107
intermediate degree polynomial, there's, we have a D equals two in our example on

78
00:03:33,107 --> 00:03:38,049
the previous slide, we're going to have a much lower cross validation error, because

79
00:03:38,049 --> 00:03:43,110
we're just fitting, finding a much better fit to the data. And conversely, if D were

80
00:03:43,110 --> 00:03:47,874
too high, so if D took on, say, a value of four, then we're getting over fitting, and

81
00:03:47,874 --> 00:03:52,669
so we ended with a high value for cross validation error. So, if you were to. vary

82
00:03:52,669 --> 00:03:57,854
this smoothly and plot the curve. You might end up with a curve like that. Where,

83
00:03:57,854 --> 00:04:03,737
that's J.C.V. Of staza. Indicating that you plot J. Tesla's data, you get

84
00:04:03,737 --> 00:04:09,465
something very similar. And so, this sort of plot also helps us to better understand

85
00:04:09,465 --> 00:04:13,829
the notions of bias and variance. Concretely, suppose you've applied a

86
00:04:13,829 --> 00:04:18,447
learning algorithm, and it's not performing as well as you were hoping.

87
00:04:18,447 --> 00:04:23,507
So, if your cross-validation set error, or your test set error is high. How can we

88
00:04:23,507 --> 00:04:28,758
figure out if the learning algorithm is suffering from high bias or if it's suffer

89
00:04:28,758 --> 00:04:34,130
from high variance? So the setting of the cause validation error being high,

90
00:04:34,130 --> 00:04:39,789
corresponds to either this regime or this regime. So this regime on the left

91
00:04:39,789 --> 00:04:45,747
corresponds to a high bias problem. That is, if you're fitting a overly low order

92
00:04:45,747 --> 00:04:51,556
polynomial, such as a D=1. When we really needed a higher order polynomial to fit

93
00:04:51,556 --> 00:04:57,513
the data. Whereas in contrast, this regime corresponds to a high variance problem.

94
00:04:57,513 --> 00:05:03,247
That is, if D, the degree of polynomial was too large for the data set that we

95
00:05:03,247 --> 00:05:08,535
have. And this figure just has a clue for how to distinguish between these two

96
00:05:08,535 --> 00:05:15,790
cases. Concretely for the high bias case.That is the case of under fitting. What we

97
00:05:15,790 --> 00:05:21,790
find is that both the cross validation error and the trading error are going to

98
00:05:21,790 --> 00:05:29,770
be high. So if your algorithm is suffering from a bias problem. The training set

99
00:05:29,770 --> 00:05:38,162
error, will be high. And you might find that the cross validation error will also

100
00:05:38,162 --> 00:05:45,271
be high. It might be a close. Maybe just slightly higher than a training error. And

101
00:05:45,271 --> 00:05:52,211
so, if you see this combination that's a sign your algorithm may be suffering from

102
00:05:52,211 --> 00:05:58,981
high bias. In contrast if your algorithm is suffering from high variance then if

103
00:05:58,981 --> 00:06:05,921
you look here. We'll notice that J-train that is the training error is going to be

104
00:06:05,921 --> 00:06:13,626
low. That is your fitting the training set very well. Where as your, cross validation

105
00:06:13,626 --> 00:06:18,575
error. Assuming that this is say the squared era. Which we're trying to

106
00:06:18,575 --> 00:06:22,757
minimize . Where as in contrast, your error on the cross

107
00:06:22,757 --> 00:06:28,080
validation set or your cross function in the cross validation set will be much bigger

108
00:06:28,080 --> 00:06:32,884
Than your training set error. So, there's a double greater than sign. That's the

109
00:06:32,884 --> 00:06:37,935
math symbol for much greater than, denoted by two greater than signs. And so, if you

110
00:06:37,935 --> 00:06:43,047
see this combination of values then that might give you, that's a clue that your

111
00:06:43,047 --> 00:06:47,482
learning algorithm maybe suffering from high variance. And might be over

112
00:06:47,482 --> 00:06:51,732
emphasizing. And the key that distinguishes these two cases is if you

113
00:06:51,732 --> 00:06:56,844
have a high bias problem your training set error will also be high. Your hypothesis

114
00:06:56,844 --> 00:07:02,080
is just not fitting the training set well. And if you have a high variance problem.

115
00:07:02,080 --> 00:07:06,852
Your training set error will usually be low. That is much lower than your cross

116
00:07:06,852 --> 00:07:11,684
validation error. So hopefully that gives you a somewhat better understanding of the

117
00:07:11,684 --> 00:07:15,845
two problems of bias and variants. I still have a lot more to say about bias and

118
00:07:15,845 --> 00:07:19,954
variants in the next few videos. But what we'll see later is that by diagnosing

119
00:07:19,954 --> 00:07:24,011
whether a learning algorithm may be suffering from high bias or high variance,

120
00:07:24,011 --> 00:07:28,432
we'll show you even more details of how to do that in later videos. We'll see that by

121
00:07:28,432 --> 00:07:32,697
figuring out whether a learning algorithm may be suffering from high bias or high

122
00:07:32,697 --> 00:07:36,806
variance, or a combination of both, that, that would give us much better guidance

123
00:07:36,806 --> 00:07:42,367
promising things to try in order to improve the performance of a learning algorithm.

